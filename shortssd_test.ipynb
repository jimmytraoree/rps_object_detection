{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ssd7test.ipynb",
      "provenance": [],
      "mount_file_id": "1RN-kMEEEFxQpTIN7mFVgeUqh3cMCypMT",
      "authorship_tag": "ABX9TyN15JczvZseNqahmI8KOKN7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimmytraoree/rps_object_detection/blob/master/shortssd_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppVQatViltPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp -r /content/drive/My\\ Drive/ssd/ssd_keras /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U_FCE5qmFqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/ssd_keras/ssd_keras')\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.optimizers import Adam\n",
        "from imageio import imread\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from models.keras_ssd7 import build_model\n",
        "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
        "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
        "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
        "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
        "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
        "\n",
        "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
        "\n",
        "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
        "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
        "from data_generator.object_detection_2d_geometric_ops import Resize\n",
        "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxwca9Z9mVUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_height = 360 # Height of the input images\n",
        "img_width = 640 # Width of the input images\n",
        "img_channels = 3 # Number of color channels of the input images\n",
        "intensity_mean = 127.5 # Set this to your preference (maybe `None`). The current settings transform the input pixel values to the interval `[-1,1]`.\n",
        "intensity_range = 127.5 # Set this to your preference (maybe `None`). The current settings transform the input pixel values to the interval `[-1,1]`.\n",
        "n_classes = 3 # Number of positive classes\n",
        "scales = [0.08, 0.16, 0.32, 0.64, 0.96] # An explicit list of anchor box scaling factors. If this is passed, it will override `min_scale` and `max_scale`.\n",
        "aspect_ratios = [0.5, 1.0, 2.0] # The list of aspect ratios for the anchor boxes\n",
        "two_boxes_for_ar1 = True # Whether or not you want to generate two anchor boxes for aspect ratio 1\n",
        "steps = None # In case you'd like to set the step sizes for the anchor box grids manually; not recommended\n",
        "offsets = None # In case you'd like to set the offsets for the anchor box grids manually; not recommended\n",
        "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
        "variances = [1.0, 1.0, 1.0, 1.0] # The list of variances by which the encoded target coordinates are scaled\n",
        "normalize_coords = True # Whether or not the model is supposed to use coordinates relative to the image size\n",
        "\n",
        "# 1: Build the Keras model\n",
        "\n",
        "K.clear_session() # Clear previous models from memory.\n",
        "\n",
        "model = build_model(image_size=(img_height, img_width, img_channels),\n",
        "                    n_classes=n_classes,\n",
        "                    mode='inference',\n",
        "                    l2_regularization=0.0005,\n",
        "                    scales=scales,\n",
        "                    aspect_ratios_global=aspect_ratios,\n",
        "                    aspect_ratios_per_layer=None,\n",
        "                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
        "                    steps=steps,\n",
        "                    offsets=offsets,\n",
        "                    clip_boxes=clip_boxes,\n",
        "                    variances=variances,\n",
        "                    normalize_coords=normalize_coords,\n",
        "                    subtract_mean=intensity_mean,\n",
        "                    divide_by_stddev=intensity_range)\n",
        "\n",
        "# 2: Optional: Load some weights\n",
        "\n",
        "model.load_weights('/content/drive/My Drive/ssd/weights/ssd7_training(vcc+egohands+rps)/ssd7_epoch-29_loss-0.8292_val_loss-0.7989.h5', by_name=True)\n",
        "\n",
        "# 3: Instantiate an Adam optimizer and the SSD loss function and compile the model\n",
        "\n",
        "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
        "\n",
        "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66xdEAbAnSvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "orig_images = [] # Store the images here.\n",
        "input_images = [] # Store resized versions of the images here.\n",
        "\n",
        "# We'll only load one image in this example.\n",
        "img_path = '/content/drive/My Drive/ssd/datasets/examples/hand04.jpg'\n",
        "\n",
        "orig_images.append(imread(img_path))\n",
        "img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "img = image.img_to_array(img) \n",
        "input_images.append(img)\n",
        "input_images = np.array(input_images)\n",
        "\n",
        "y_pred = model.predict(input_images)\n",
        "\n",
        "confidence_threshold = 0.75\n",
        "\n",
        "y_pred_thresh = [y_pred[k][y_pred[k,:,1] > confidence_threshold] for k in range(y_pred.shape[0])]\n",
        "\n",
        "np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
        "print(\"Predicted boxes:\\n\")\n",
        "print('   class   conf xmin   ymin   xmax   ymax')\n",
        "print(y_pred_thresh[0])\n",
        "\n",
        "# Display the image and draw the predicted boxes onto it.\n",
        "\n",
        "# Set the colors for the bounding boxes\n",
        "colors = plt.cm.hsv(np.linspace(0, 1, 4)).tolist()\n",
        "classes = ['background',\n",
        "           'rock', 'paper', 'scissors']\n",
        "\n",
        "plt.figure(figsize=(20,12))\n",
        "plt.imshow(orig_images[0])\n",
        "\n",
        "current_axis = plt.gca()\n",
        "\n",
        "for box in y_pred_thresh[0]:\n",
        "    # Transform the predicted bounding boxes for the 300x300 image to the original image dimensions.\n",
        "    xmin = box[2] * orig_images[0].shape[1] / img_width\n",
        "    ymin = box[3] * orig_images[0].shape[0] / img_height\n",
        "    xmax = box[4] * orig_images[0].shape[1] / img_width\n",
        "    ymax = box[5] * orig_images[0].shape[0] / img_height\n",
        "    color = colors[int(box[0])]\n",
        "    label = '{}: {:.2f}'.format(classes[int(box[0])], box[1])\n",
        "    current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color=color, fill=False, linewidth=2))  \n",
        "    current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor':color, 'alpha':1.0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xntTee1mKuXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap = cv2.VideoCapture('/content/drive/My Drive/ssd/datasets/test data/video2.mp4')\n",
        "\n",
        "while(True):\n",
        "\n",
        "    input_images = []\n",
        "\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Our operations on the frame come here\n",
        "    input_images.append(frame)\n",
        "    input_images = np.array(input_images)\n",
        "\n",
        "    prediction = model.predict(input_images)\n",
        "\n",
        "    confidence_threshold = 0.75\n",
        "\n",
        "    y_pred_thresh = [prediction[k][prediction[k, :, 1] > confidence_threshold] for k in range(prediction.shape[0])]\n",
        "\n",
        "    np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
        "    print(\"Predicted boxes:\\n\")\n",
        "    print('   class   conf xmin   ymin   xmax   ymax')\n",
        "    print(y_pred_thresh[0])\n",
        "\n",
        "    for box in y_pred_thresh[0]:\n",
        "        xmin = box[2]\n",
        "        Xmin = xmin.item()\n",
        "        ymin = box[3]\n",
        "        Ymin = ymin.item()\n",
        "        xmax = box[4]\n",
        "        Xmax = xmax.item()\n",
        "        ymax = box[5]\n",
        "        Ymax = ymax.item()\n",
        "        cv2.rectangle(frame, (int(Xmin),int(Ymin)), (int(Xmax),int(Ymax)), (0, 0, 255), 3)\n",
        "\n",
        "    # Display the resulting frame\n",
        "    cv2_imshow(frame)\n",
        "    #cv2.imshow('frame',frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# When everything done, release the capture\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}