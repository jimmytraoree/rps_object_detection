{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fullssdtest_v1.ipynb",
      "provenance": [],
      "mount_file_id": "1RCL5_LPWwMjKGI2tLK8AkWs1qO8gO73A",
      "authorship_tag": "ABX9TyMcVIBaFOAm3FaYA9NzziKE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimmytraoree/rps_object_detection/blob/master/fullssd_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiWi4mma0hmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp -r /content/drive/My\\ Drive/ssd/ssd_keras /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IZlSYnF0wZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/ssd_keras/ssd_keras')\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.optimizers import Adam\n",
        "from imageio import imread\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from models.keras_ssd300 import ssd_300\n",
        "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
        "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
        "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
        "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
        "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
        "\n",
        "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
        "\n",
        "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
        "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
        "from data_generator.object_detection_2d_geometric_ops import Resize\n",
        "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR_0X2PG01Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_height = 360 # Height of the model input images\n",
        "img_width = 640 # Width of the model input images\n",
        "img_channels = 3 # Number of color channels of the model input images\n",
        "mean_color = [123, 117, 104] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
        "swap_channels = [2, 1, 0] # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
        "n_classes = 3 # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
        "scales = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05]\n",
        "aspect_ratios = [[1.0, 2.0, 0.5],\n",
        "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
        "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
        "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
        "                 [1.0, 2.0, 0.5],\n",
        "                 [1.0, 2.0, 0.5]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
        "two_boxes_for_ar1 = True\n",
        "steps = [8, 16, 32, 64, 100, 300] # The space between two adjacent anchor box center points for each predictor layer.\n",
        "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
        "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
        "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are divided as in the original implementation\n",
        "normalize_coords = True\n",
        "# 1: Build the Keras model.\n",
        "\n",
        "K.clear_session() # Clear previous models from memory.\n",
        "\n",
        "model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
        "                n_classes=n_classes,\n",
        "                mode='inference',\n",
        "                l2_regularization=0.0005,\n",
        "                scales=scales,\n",
        "                aspect_ratios_per_layer=aspect_ratios,\n",
        "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
        "                steps=steps,\n",
        "                offsets=offsets,\n",
        "                clip_boxes=clip_boxes,\n",
        "                variances=variances,\n",
        "                normalize_coords=normalize_coords,\n",
        "                subtract_mean=mean_color,\n",
        "                swap_channels=swap_channels)\n",
        "\n",
        "# 2: Load some weights into the model.\n",
        "\n",
        "weights_path = '/content/drive/My Drive/ssd/weights/fullssd_(vcc+egohands+rps)/epoch.h5'\n",
        "\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
        "\n",
        "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s8U7S0aKZc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "orig_images = [] # Store the images here.\n",
        "input_images = [] # Store resized versions of the images here.\n",
        "\n",
        "# We'll only load one image in this example.\n",
        "img_path = '/content/drive/My Drive/ssd/datasets/test data/hand01 (7).jpg'\n",
        "\n",
        "orig_images.append(imread(img_path))\n",
        "img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "img = image.img_to_array(img) \n",
        "input_images.append(img)\n",
        "input_images = np.array(input_images)\n",
        "\n",
        "y_pred = model.predict(input_images)\n",
        "\n",
        "confidence_threshold = 0.75\n",
        "\n",
        "y_pred_thresh = [y_pred[k][y_pred[k,:,1] > confidence_threshold] for k in range(y_pred.shape[0])]\n",
        "\n",
        "np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
        "print(\"Predicted boxes:\\n\")\n",
        "print('   class   conf xmin   ymin   xmax   ymax')\n",
        "print(y_pred_thresh[0])\n",
        "\n",
        "# Display the image and draw the predicted boxes onto it.\n",
        "\n",
        "# Set the colors for the bounding boxes\n",
        "colors = plt.cm.hsv(np.linspace(0, 1, 4)).tolist()\n",
        "classes = ['background',\n",
        "           'rock', 'paper', 'scissors']\n",
        "\n",
        "plt.figure(figsize=(20,12))\n",
        "plt.imshow(orig_images[0])\n",
        "\n",
        "current_axis = plt.gca()\n",
        "\n",
        "for box in y_pred_thresh[0]:\n",
        "    # Transform the predicted bounding boxes for the 300x300 image to the original image dimensions.\n",
        "    xmin = box[2] * orig_images[0].shape[1] / img_width\n",
        "    ymin = box[3] * orig_images[0].shape[0] / img_height\n",
        "    xmax = box[4] * orig_images[0].shape[1] / img_width\n",
        "    ymax = box[5] * orig_images[0].shape[0] / img_height\n",
        "    color = colors[int(box[0])]\n",
        "    label = '{}: {:.2f}'.format(classes[int(box[0])], box[1])\n",
        "    current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color=color, fill=False, linewidth=2))  \n",
        "    current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor':color, 'alpha':1.0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzzTs_DMKt7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap = cv2.VideoCapture('/content/drive/My Drive/ssd/datasets/test data/video2.mp4')\n",
        "\n",
        "while(True):\n",
        "\n",
        "    input_images = []\n",
        "\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Our operations on the frame come here\n",
        "    input_images.append(frame)\n",
        "    input_images = np.array(input_images)\n",
        "\n",
        "    prediction = model.predict(input_images)\n",
        "\n",
        "    confidence_threshold = 0.75\n",
        "\n",
        "    y_pred_thresh = [prediction[k][prediction[k, :, 1] > confidence_threshold] for k in range(prediction.shape[0])]\n",
        "\n",
        "    np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
        "    print(\"Predicted boxes:\\n\")\n",
        "    print('   class   conf xmin   ymin   xmax   ymax')\n",
        "    print(y_pred_thresh[0])\n",
        "\n",
        "    for box in y_pred_thresh[0]:\n",
        "        xmin = box[2]\n",
        "        Xmin = xmin.item()\n",
        "        ymin = box[3]\n",
        "        Ymin = ymin.item()\n",
        "        xmax = box[4]\n",
        "        Xmax = xmax.item()\n",
        "        ymax = box[5]\n",
        "        Ymax = ymax.item()\n",
        "        cv2.rectangle(frame, (int(Xmin),int(Ymin)), (int(Xmax),int(Ymax)), (0, 0, 255), 3)\n",
        "\n",
        "    # Display the resulting frame\n",
        "    cv2_imshow(frame)\n",
        "    #cv2.imshow('frame',frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# When everything done, release the capture\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}