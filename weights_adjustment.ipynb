{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "weights_adjustment.ipynb",
      "provenance": [],
      "mount_file_id": "13oHolVoxp6CiBqVtSClh_0-uNE8jzTDA",
      "authorship_tag": "ABX9TyOEE/4YG2b1RyDEQsLN+Vcg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimmytraoree/rps_object_detection/blob/master/weights_adjustment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97js31KUxGPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp -r /content/drive/My\\ Drive/ssd/ssd_keras /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuNg_KdPxPv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/ssd_keras')\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "from misc_utils.tensor_sampling_utils import sample_tensors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSwtIhoQxS00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Set the path for the source weights file you want to load.\n",
        "\n",
        "weights_source_path = '/content/drive/My Drive/ssd/datasetsh5/VGG_coco_SSD_300x300_iter_400000.h5'\n",
        "\n",
        "# TODO: Set the path and name for the destination weights file\n",
        "#       that you want to create.\n",
        "\n",
        "weights_destination_path = '/content/drive/My Drive/ssd/datasetsh5/1class_subsapled_VGG_coco_SSD_300x300_iter_400000.h5'\n",
        "\n",
        "# Make a copy of the weights file.\n",
        "shutil.copy(weights_source_path, weights_destination_path)\n",
        "\n",
        "# Load both the source weights file and the copy we made.\n",
        "# We will load the original weights file in read-only mode so that we can't mess up anything.\n",
        "weights_source_file = h5py.File(weights_source_path, 'r')\n",
        "weights_destination_file = h5py.File(weights_destination_path)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpjgF3esxiIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "classifier_names = ['conv4_3_norm_mbox_conf',\n",
        "                    'fc7_mbox_conf',\n",
        "                    'conv6_2_mbox_conf',\n",
        "                    'conv7_2_mbox_conf',\n",
        "                    'conv8_2_mbox_conf',\n",
        "                    'conv9_2_mbox_conf']\n",
        "\n",
        "conv4_3_norm_mbox_conf_kernel = weights_source_file[classifier_names[0]][classifier_names[0]]['kernel:0']\n",
        "conv4_3_norm_mbox_conf_bias = weights_source_file[classifier_names[0]][classifier_names[0]]['bias:0']\n",
        "\n",
        "print(\"Shape of the '{}' weights:\".format(classifier_names[0]))\n",
        "print()\n",
        "print(\"kernel:\\t\", conv4_3_norm_mbox_conf_kernel.shape)\n",
        "print(\"bias:\\t\", conv4_3_norm_mbox_conf_bias.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_BMK5sbxktO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Set the number of classes in the source weights file. Note that this number must include\n",
        "#       the background class, so for MS COCO's 80 classes, this must be 80 + 1 = 81.\n",
        "n_classes_source = 81\n",
        "# TODO: Set the indices of the classes that you want to pick for the sub-sampled weight tensors.\n",
        "#       In case you would like to just randomly sample a certain number of classes, you can just set\n",
        "#       `classes_of_interest` to an integer instead of the list below. Either way, don't forget to\n",
        "#       include the background class. That is, if you set an integer, and you want `n` positive classes,\n",
        "#       then you must set `classes_of_interest = n + 1`.\n",
        "#classes_of_interest = [0, 3, 8, 1, 2, 10, 4, 6, 12]\n",
        "classes_of_interest = 2 # Uncomment this in case you want to just randomly sub-sample the last axis instead of providing a list of indices.\n",
        "\n",
        "for name in classifier_names:\n",
        "    # Get the trained weights for this layer from the source HDF5 weights file.\n",
        "    kernel = weights_source_file[name][name]['kernel:0'].value\n",
        "    bias = weights_source_file[name][name]['bias:0'].value\n",
        "\n",
        "    # Get the shape of the kernel. We're interested in sub-sampling\n",
        "    # the last dimension, 'o'.\n",
        "    height, width, in_channels, out_channels = kernel.shape\n",
        "    \n",
        "    # Compute the indices of the elements we want to sub-sample.\n",
        "    # Keep in mind that each classification predictor layer predicts multiple\n",
        "    # bounding boxes for every spatial location, so we want to sub-sample\n",
        "    # the relevant classes for each of these boxes.\n",
        "    if isinstance(classes_of_interest, (list, tuple)):\n",
        "        subsampling_indices = []\n",
        "        for i in range(int(out_channels/n_classes_source)):\n",
        "            indices = np.array(classes_of_interest) + i * n_classes_source\n",
        "            subsampling_indices.append(indices)\n",
        "        subsampling_indices = list(np.concatenate(subsampling_indices))\n",
        "    elif isinstance(classes_of_interest, int):\n",
        "        subsampling_indices = int(classes_of_interest * (out_channels/n_classes_source))\n",
        "    else:\n",
        "        raise ValueError(\"`classes_of_interest` must be either an integer or a list/tuple.\")\n",
        "    \n",
        "    # Sub-sample the kernel and bias.\n",
        "    # The `sample_tensors()` function used below provides extensive\n",
        "    # documentation, so don't hesitate to read it if you want to know\n",
        "    # what exactly is going on here.\n",
        "    new_kernel, new_bias = sample_tensors(weights_list=[kernel, bias],\n",
        "                                          sampling_instructions=[height, width, in_channels, subsampling_indices],\n",
        "                                          axes=[[3]], # The one bias dimension corresponds to the last kernel dimension.\n",
        "                                          init=['gaussian', 'zeros'],\n",
        "                                          mean=0.0,\n",
        "                                          stddev=0.005)\n",
        "    \n",
        "    # Delete the old weights from the destination file.\n",
        "    del weights_destination_file[name][name]['kernel:0']\n",
        "    del weights_destination_file[name][name]['bias:0']\n",
        "    # Create new datasets for the sub-sampled weights.\n",
        "    weights_destination_file[name][name].create_dataset(name='kernel:0', data=new_kernel)\n",
        "    weights_destination_file[name][name].create_dataset(name='bias:0', data=new_bias)\n",
        "\n",
        "# Make sure all data is written to our output file before this sub-routine exits.\n",
        "weights_destination_file.flush()\n",
        "\n",
        "conv4_3_norm_mbox_conf_kernel = weights_destination_file[classifier_names[0]][classifier_names[0]]['kernel:0']\n",
        "conv4_3_norm_mbox_conf_bias = weights_destination_file[classifier_names[0]][classifier_names[0]]['bias:0']\n",
        "\n",
        "print(\"Shape of the '{}' weights:\".format(classifier_names[0]))\n",
        "print()\n",
        "print(\"kernel:\\t\", conv4_3_norm_mbox_conf_kernel.shape)\n",
        "print(\"bias:\\t\", conv4_3_norm_mbox_conf_bias.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}